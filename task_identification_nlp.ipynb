{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary depencencies**"
      ],
      "metadata": {
        "id": "IXkNtTasnkUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SzSJR6Chje3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7741c7-3a44-446e-bb17-87b6151eca39",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dateparser\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n",
            "Downloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dateparser\n",
            "Successfully installed dateparser-1.2.1\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "!pip install dateparser\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_verbs = [\n",
        "    \"must\", \"should\", \"might\", \"can\", \"could\", \"shall\", \"will\", \"would\",\n",
        "    \"may\", \"ought\", \"dare\", \"let\", \"do\", \"does\", \"had better\", \"better\",\n",
        "    \"needn't\", \"shall not\", \"shall\"\n",
        "] #These words clearly indicate a task in any paragraph. If there are additional words that signify a task, they can be included to enhance performance.\n",
        "to_form_verbs = [\n",
        "    \"has\", \"have\", \"had\", \"used\", \"need\", \"needs\", \"ought\", \"required\",\n",
        "    \"want\", \"wants\", \"wish\", \"wished\", \"supposed\", \"going\", \"bound\",\n",
        "    \"determined\", \"expected\", \"forced\", \"obliged\", \"intended\", \"aim\",\n",
        "    \"aims\", \"plan\", \"plans\", \"set\", \"decided\", \"attempt\", \"attempts\",\n",
        "    \"fail\", \"fails\", \"manage\", \"manages\", \"struggle\", \"struggles\"\n",
        "] #When the word \"to\" follows these words, it indicates a task that needs to be completed.\n",
        "stopwords_list = set(stopwords.words('english'))\n",
        "be_form= [\"be\", \"am\", \"is\", \"are\", \"was\", \"were\", \"being\", \"been\",\n",
        "         \"have\", \"has\", \"had\", \"having\"] #to remove these words from finding action words\n",
        "pronouns=['he','she','it','they','we'] #pronouns to identify the person whom has to do the task"
      ],
      "metadata": {
        "id": "1T5D5ZvdtNVV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocessing(sentences):\n",
        "\n",
        "  #removing html tags from the input sentences\n",
        "  tag_re = re.compile(r\"<[^>]+>\")\n",
        "  sentences = tag_re.sub('', sentences)\n",
        "\n",
        "  #making sentences in to splits of each sentences\n",
        "\n",
        "  sents = sent_tokenize(sentences)\n",
        "  sent_words = []\n",
        "  for i in sents:\n",
        "    a = list(i.split())\n",
        "    sent_words.append(a)\n",
        "\n",
        "  #converting the text into lower case and removing punctuations and numbers\n",
        "  sentences = re.sub(r'[^a-zA-Z\\s]', '', sentences)\n",
        "  sentences = re.sub(r\"\\b[a-zA-Z]\\b\", '', sentences)\n",
        "\n",
        "  #remove multiple spaces\n",
        "  sentences = re.sub(r'\\s+', ' ', sentences).strip()\n",
        "\n",
        "  #spliiting the sentences into individual words\n",
        "  words = sentences.split()\n",
        "  pos_tags = pos_tag(words)\n",
        "\n",
        "  #finding the action words in the sentences\n",
        "  action_words = [word for word, tag in pos_tags if tag.startswith('VB') if word not in be_form ]\n",
        "\n",
        "  #finding the subject from the data\n",
        "  subject = [word for word, tag in pos_tags if tag.startswith('NN') if word.istitle()]\n",
        "\n",
        "  #extracting the task from the input text\n",
        "  for i in action_words:\n",
        "    for j in range(len(words)):\n",
        "      if words[j]==i and words[j-1] in action_verbs:\n",
        "        print(subject[0],words[j-1],i,\" \".join(' '.join(sublist) for sublist in [sent_words[a][b+1:] for a in range(len(sent_words)) for b in range(len(sent_words[a])) if sent_words[a][b]==i]))\n",
        "      elif words[j]==i and words[j-2] in to_form_verbs:\n",
        "        print(subject[0],words[j-2],\"to\",i,\" \".join(' '.join(sublist) for sublist in [sent_words[a][b+1:] for a in range(len(sent_words)) for b in range(len(sent_words[a])) if sent_words[a][b]==i]))"
      ],
      "metadata": {
        "id": "hYfcZ0CLNQGf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import dateparser\n",
        "\n",
        "def extract_time_data(text):\n",
        "    # Regex patterns for different time-related mentions\n",
        "    day_pattern = r'\\b(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)\\b'\n",
        "    date_pattern = r'\\b(\\d{1,2})(?:st|nd|rd|th)?\\s+of\\s+\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\b'\n",
        "    time_pattern = r'\\b(\\d{1,2}(?::\\d{2})?\\s?(?:AM|PM|am|pm)?)\\b'\n",
        "    period_pattern = r'\\b(morning|afternoon|evening|night|midnight|noon|now)\\b'\n",
        "\n",
        "    # Extract matches\n",
        "    days = re.findall(day_pattern, text, re.IGNORECASE)\n",
        "    dates = re.findall(date_pattern, text, re.IGNORECASE)\n",
        "    times = re.findall(time_pattern, text, re.IGNORECASE)\n",
        "    periods = re.findall(period_pattern, text, re.IGNORECASE)\n",
        "\n",
        "    # Convert dates to full format\n",
        "    formatted_dates = [dateparser.parse(f\"{d[0]} {d[1]}\").strftime('%d %B') for d in dates]\n",
        "\n",
        "    return {\n",
        "        \"days\": days,\n",
        "        \"dates\": formatted_dates,\n",
        "        \"times\": times,\n",
        "        \"periods\": periods\n",
        "    }"
      ],
      "metadata": {
        "id": "vAT_gttPVsHP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Rahul wakes up early every day. He goes to college in the morning and comes back at 3 pm. At present,<html> Rahul is outside. He has to buy the snacks for all of us. He is very good in his studies. He should clean the room before 5pm\"\n",
        "print(preprocessing(text))\n",
        "print(extract_time_data(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n38bmhqNa2w",
        "outputId": "d7914cb8-cd02-4411-e2d7-a92cb01b7068"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rahul has to buy the snacks for all of us.\n",
            "Rahul should clean the room before 5pm\n",
            "None\n",
            "{'days': [], 'dates': [], 'times': ['3 pm', '5pm'], 'periods': ['morning']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Sophie starts her day with a cup of coffee and a morning walk. She spends a few hours attending online lectures. Before lunch, she has to submit her assignment on machine learning. In the afternoon, she takes a short nap and then helps her brother with his studies. In the evening, she enjoys watching her favorite TV series.\"\n",
        "print(preprocessing(text))\n",
        "print(extract_time_data(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZql7fOoKHb7",
        "outputId": "bf94165b-bb07-4071-c26f-91261529c0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sophie has to submit her assignment on machine learning.\n",
            "(['starts', 'spends', 'attending', 'submit', 'takes', 'helps', 'enjoys', 'watching'], ['Sophie'], [['Sophie', 'starts', 'her', 'day', 'with', 'a', 'cup', 'of', 'coffee', 'and', 'a', 'morning', 'walk.'], ['She', 'spends', 'a', 'few', 'hours', 'attending', 'online', 'lectures.'], ['Before', 'lunch,', 'she', 'has', 'to', 'submit', 'her', 'assignment', 'on', 'machine', 'learning.'], ['In', 'the', 'afternoon,', 'she', 'takes', 'a', 'short', 'nap', 'and', 'then', 'helps', 'her', 'brother', 'with', 'his', 'studies.'], ['In', 'the', 'evening,', 'she', 'enjoys', 'watching', 'her', 'favorite', 'TV', 'series.']])\n",
            "{'days': [], 'dates': [], 'times': [], 'periods': ['morning', 'afternoon', 'evening']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Ryan wakes up early every morning and goes for a jog in the park. After returning home, he takes a quick shower and has breakfast. He must complete his project report before heading to work. Later in the evening, he plans to meet his friends for dinner. He usually spends some time reading before going to bed.\"\n",
        "print(preprocessing(text))\n",
        "print(extract_time_data(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Menl8UNyi1",
        "outputId": "5ea5bece-0978-4580-9ff6-c443a3c8e0b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ryan must complete his project report before heading to work.\n",
            "Ryan plans to meet his friends for dinner.\n",
            "Ryan going to bed \n",
            "(['wakes', 'goes', 'returning', 'takes', 'complete', 'heading', 'work', 'plans', 'meet', 'spends', 'reading', 'going', 'bed'], ['Ryan'], [['Ryan', 'wakes', 'up', 'early', 'every', 'morning', 'and', 'goes', 'for', 'a', 'jog', 'in', 'the', 'park.'], ['After', 'returning', 'home,', 'he', 'takes', 'a', 'quick', 'shower', 'and', 'has', 'breakfast.'], ['He', 'must', 'complete', 'his', 'project', 'report', 'before', 'heading', 'to', 'work.'], ['Later', 'in', 'the', 'evening,', 'he', 'plans', 'to', 'meet', 'his', 'friends', 'for', 'dinner.'], ['He', 'usually', 'spends', 'some', 'time', 'reading', 'before', 'going', 'to', 'bed.']])\n",
            "{'days': [], 'dates': [], 'times': [], 'periods': ['morning', 'evening']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Amit wakes up early every morning and goes for a jog in the park. He enjoys reading books and often visits the library in the evening. Today, he has to submit his project report before noon. After that, he must call his professor to discuss his research findings. In the afternoon, he needs to buy groceries for the week. His mother reminded him that he should pay the electricity bill before the due date. Later, Amit plans to meet his friends for a study session. Before going to bed, he has to complete his assignment and review notes for the upcoming exam.\"\n",
        "print(preprocessing(text))\n",
        "print(extract_time_data(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UiXiIvLnNn",
        "outputId": "2090e92c-951b-449b-e7f2-83fcceeb74e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amit has to submit his project report before noon.\n",
            "Amit must call his professor to discuss his research findings.\n",
            "Amit needs to buy groceries for the week.\n",
            "Amit should pay the electricity bill before the due date.\n",
            "Amit plans to meet his friends for a study session.\n",
            "Amit going to bed \n",
            "Amit has to complete his assignment and review notes for the upcoming exam.\n",
            "(['wakes', 'goes', 'enjoys', 'reading', 'visits', 'submit', 'call', 'discuss', 'needs', 'buy', 'reminded', 'pay', 'plans', 'meet', 'going', 'bed', 'complete'], ['Amit', 'Today', 'Later', 'Amit'], [['Amit', 'wakes', 'up', 'early', 'every', 'morning', 'and', 'goes', 'for', 'a', 'jog', 'in', 'the', 'park.'], ['He', 'enjoys', 'reading', 'books', 'and', 'often', 'visits', 'the', 'library', 'in', 'the', 'evening.'], ['Today,', 'he', 'has', 'to', 'submit', 'his', 'project', 'report', 'before', 'noon.'], ['After', 'that,', 'he', 'must', 'call', 'his', 'professor', 'to', 'discuss', 'his', 'research', 'findings.'], ['In', 'the', 'afternoon,', 'he', 'needs', 'to', 'buy', 'groceries', 'for', 'the', 'week.'], ['His', 'mother', 'reminded', 'him', 'that', 'he', 'should', 'pay', 'the', 'electricity', 'bill', 'before', 'the', 'due', 'date.'], ['Later,', 'Amit', 'plans', 'to', 'meet', 'his', 'friends', 'for', 'a', 'study', 'session.'], ['Before', 'going', 'to', 'bed,', 'he', 'has', 'to', 'complete', 'his', 'assignment', 'and', 'review', 'notes', 'for', 'the', 'upcoming', 'exam.']])\n",
            "{'days': [], 'dates': [], 'times': [], 'periods': ['morning', 'evening', 'noon', 'afternoon']}\n"
          ]
        }
      ]
    }
  ]
}